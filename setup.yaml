comet_project_name : Vertex_Finder_E2E
comet_experiment_name : CMSSW_z0_128MaxPt
description : Baseline Model CMSSW_z0 128MaxPt

weight_features : ['rescaled_trk_word_pT','rescaled_trk_word_MVAquality','rescaled_trk_word_eta'] #['abs_trk_word_pT','trk_word_MVAquality','abs_trk_word_eta']  #['rescaled_trk_word_pT','rescaled_trk_word_MVAquality','rescaled_trk_word_eta'] #
track_features :  ['rescaled_trk_word_pT','rescaled_trk_word_MVAquality','rescaled_trk_z0_res']  #['abs_trk_word_pT','trk_word_MVAquality','trk_z0_res']  #['rescaled_trk_word_pT','rescaled_trk_word_MVAquality','rescaled_trk_z0_res']  #

UnquantisedModelName : Unquantised_model
QuantisedModelName : Quantised_model
QuantisedPrunedModelName : Quantised_model_prune_iteration_9

prune_iterations : 8

nbins : 256

data_folder : /home/cebrown/Documents/Datasets/VertexDatasets/OldKFGTTData_EmuTQ/NewData

Nlatent : 0

starting_lr : 0.005
qtrain_starting_lr : 0.0001

epochs : 18
qtrain_epochs : 8

z0_loss_weight : 1.0
crossentropy_loss_weight : 1.2
qtrain_z0_loss_weight : 1.0
qtrain_crossentropy_loss_weight : 1.2
Huber_delta : 0.6

l1regloss : 1e-3
l2regloss : 1e-10
nweightnodes : 10
nweightlayers : 2
nassocnodes : 20
nassoclayers : 2

relative_weight_max : [0.0,0.001,0.005,0.01,0.015,0.03,0.05,0.08,0.1,0.12]

# QConfig:
#   weight_1: 
#     kernel_quantizer: quantized_bits(7,1,alpha=1) #8,2
#     bias_quantizer: quantized_bits(5,1,alpha=1) #9,1
#     activation : quantized_relu(7,1) #10,2
#   weight_2:
#     kernel_quantizer : quantized_bits(7,1,alpha=1) #8,2
#     bias_quantizer : quantized_bits(5,1,alpha=1) #9,1
#     activation : quantized_relu(7,1)  #10,2
#   weight_final:
#     kernel_quantizer : quantized_bits(7,1,alpha=1)  #5,2
#     bias_quantizer : quantized_bits(5,1,alpha=1) #6,1
#     activation : quantized_relu(7,1) #10,2
#   conv_1:
#     kernel_quantizer : quantized_bits(7,1,alpha=1) #2,6
#     activation : quantized_relu(7,1) #8,2
#   PVDense:
#     kernel_quantizer : quantized_bits(16,6,alpha=1)
#     bias_quantizer : quantized_bits(16,6,alpha=1)
#   association_0 :
#     kernel_quantizer : quantized_bits(7,1,alpha=1) #12,1
#     bias_quantizer : quantized_bits(5,1,alpha=1) #8,2
#     activation : quantized_relu(7,1)
#   association_1 : 
#     kernel_quantizer : quantized_bits(7,1,alpha=1) #12,1
#     bias_quantizer : quantized_bits(5,1,alpha=1) #5,1
#     activation : quantized_relu(7,1)
#   association_final : 
#     kernel_quantizer : quantized_bits(7,1,alpha=1) #7,1
#     bias_quantizer : quantized_bits(4,1,alpha=1) #4,1


QConfig:
  weight_1: 
    kernel_quantizer: quantized_bits(9,1,alpha=1) #8,2
    bias_quantizer: quantized_bits(11,1,alpha=1) #9,1
    activation : quantized_relu(9,2) #10,2
  weight_2:
    kernel_quantizer : quantized_bits(14,1,alpha=1) #8,2
    bias_quantizer : quantized_bits(8,1,alpha=1) #9,1
    activation : quantized_relu(9,2)  #10,2
  weight_final:
    kernel_quantizer : quantized_bits(9,1,alpha=1)  #5,2
    bias_quantizer : quantized_bits(7,1,alpha=1) #6,1
    activation : quantized_relu(9,2) #10,2
  conv_1:
    kernel_quantizer : quantized_bits(10,2,alpha=1) #2,6
    activation : quantized_relu(10,2) #8,2
  PVDense:
    kernel_quantizer : quantized_bits(16,6,alpha=1)
    bias_quantizer : quantized_bits(16,6,alpha=1)
  association_0 :
    kernel_quantizer : quantized_bits(10,1,alpha=1) #12,1
    bias_quantizer : quantized_bits(7,1,alpha=1) #8,2
    activation : quantized_relu(8,2)
  association_1 : 
    kernel_quantizer : quantized_bits(13,1,alpha=1) #12,1
    bias_quantizer : quantized_bits(7,1,alpha=1) #5,1
    activation : quantized_relu(8,2)
  association_final : 
    kernel_quantizer : quantized_bits(9,1,alpha=1) #7,1
    bias_quantizer : quantized_bits(5,1,alpha=1) #4,1

